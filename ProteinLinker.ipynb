{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e40c94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from Bio import PDB\n",
    "from Bio.PDB.PDBIO import PDBIO\n",
    "from Bio.PDB import Atom, Residue, Chain, Model, Structure\n",
    "from Bio.PDB.vectors import Vector\n",
    "from scipy.special import comb\n",
    "import py3Dmol\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "983deb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PolyGLinker:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Standard amino acid geometry\n",
    "        self.ca_c_length = 1.52    # Å\n",
    "        self.c_n_length = 1.33     # Å\n",
    "        self.n_ca_length = 1.46    # Å\n",
    "        self.ca_ca_distance = 3.8  # Å\n",
    "        self.ca_c_n_angle = 117.2  # degrees\n",
    "        self.c_n_ca_angle = 121.7  # degrees\n",
    "        self.peptide_omega = 180.0 # degrees\n",
    "\n",
    "    def _optimize_control_points(self, start_pos, end_pos, start_dir, end_dir, num_residues):\n",
    "        \"\"\"Optimize control points to achieve desired path length.\"\"\"\n",
    "        target_length = (num_residues - 1) * self.ca_ca_distance\n",
    "        distance = np.linalg.norm(end_pos - start_pos)\n",
    "        \n",
    "        def objective(x):\n",
    "            # x contains scaling factors for control points\n",
    "            scale1, scale2 = x\n",
    "            p0 = start_pos\n",
    "            p1 = start_pos + start_dir * (distance * scale1)\n",
    "            p2 = end_pos - end_dir * (distance * scale2)\n",
    "            p3 = end_pos\n",
    "            \n",
    "            path_length = self._calculate_path_length((p0, p1, p2, p3))\n",
    "            return (path_length - target_length)**2\n",
    "        \n",
    "        # Optimize scaling factors\n",
    "        result = minimize(objective, [0.33, 0.33], bounds=[(0.1, 0.9), (0.1, 0.9)])\n",
    "        scale1, scale2 = result.x\n",
    "        scale1, scale2 = (.33,.33)\n",
    "        # Return optimized control points\n",
    "        return (\n",
    "            start_pos,\n",
    "            start_pos + start_dir * (distance * scale1),\n",
    "            end_pos - end_dir * (distance * scale2),\n",
    "            end_pos\n",
    "        )\n",
    "        \n",
    "    def _generate_backbone_atoms_with_direction(self, prev_c, prev_ca, current_ca, direction):\n",
    "        \"\"\"Generate backbone atoms with proper geometry.\"\"\"\n",
    "        peptide_plane_normal = np.cross(prev_c - prev_ca, direction)\n",
    "        peptide_plane_normal = peptide_plane_normal / np.linalg.norm(peptide_plane_normal)\n",
    "        \n",
    "        n_direction = np.cross(direction, peptide_plane_normal)\n",
    "        n_pos = prev_c + self.c_n_length * n_direction\n",
    "        \n",
    "        ca_pos = current_ca\n",
    "        \n",
    "        c_direction = np.cross(direction, peptide_plane_normal)\n",
    "        c_pos = ca_pos + self.ca_c_length * c_direction\n",
    "        \n",
    "        return {\n",
    "            'N': n_pos,\n",
    "            'CA': ca_pos,\n",
    "            'C': c_pos\n",
    "        }\n",
    "\n",
    "    def generate_linker(self, segment1, segment2 ):\n",
    "        \"\"\"Generate backbone coordinates for a linker using an optimized Bezier curve.\"\"\"\n",
    "        start_res =segment1.c_res\n",
    "        end_res = segment2.n_res\n",
    "        start_direction =segment1._calculate_residue_direction(start_res)* (.5 + np.random.rand() * 2)\n",
    "        end_direction = segment2._calculate_residue_direction(end_res) * (.5 + np.random.rand() * 2)\n",
    "        \n",
    "        start_ca = start_res['CA'].get_coord()\n",
    "        end_ca = end_res['CA'].get_coord()\n",
    "        \n",
    "        distance = np.linalg.norm(end_ca - start_ca)\n",
    "        # Generate a test path for the Bezier curve\n",
    "        test_control_points = (start_ca, start_ca + start_direction * (distance / 3), end_ca - end_direction * (distance / 3), end_ca)\n",
    "        test_path_length = self._calculate_path_length(test_control_points)\n",
    "        num_residues = int(np.ceil(test_path_length / self.ca_ca_distance))\n",
    "        \n",
    "         \n",
    "        \n",
    "        # Optimize control points for target path length\n",
    "        control_points = self._optimize_control_points(\n",
    "            start_ca, end_ca, start_direction, end_direction, num_residues\n",
    "        )\n",
    "        \n",
    "        # Generate points along optimized Bezier curve with equal arc length spacing\n",
    "        # First, calculate a finely sampled path\n",
    "        fine_t = np.linspace(0, 1, 1000)\n",
    "        fine_path = np.array([self._evaluate_bezier(control_points, ti) for ti in fine_t])\n",
    "                \n",
    "        # Calculate cumulative arc length at each point\n",
    "        segments = np.diff(fine_path, axis=0)\n",
    "        segment_lengths = np.sqrt(np.sum(segments**2, axis=1))\n",
    "        cumulative_length = np.concatenate(([0], np.cumsum(segment_lengths)))\n",
    "        total_length = cumulative_length[-1]\n",
    "                \n",
    "        # Generate equally spaced points based on arc length\n",
    "        target_lengths = np.linspace(0, total_length, num_residues)\n",
    "        path = np.zeros((num_residues, 3))\n",
    "                \n",
    "        # For each target length, find corresponding point on curve\n",
    "        for i, target in enumerate(target_lengths):\n",
    "            # Find index of the segment containing our target length\n",
    "            idx = np.searchsorted(cumulative_length, target)\n",
    "            if idx == 0:\n",
    "                path[i] = fine_path[0]\n",
    "            elif idx >= len(fine_path):\n",
    "                path[i] = fine_path[-1]\n",
    "            else:\n",
    "                # Interpolate between points\n",
    "                prev_idx = idx - 1\n",
    "                segment_start = cumulative_length[prev_idx]\n",
    "                segment_end = cumulative_length[idx]\n",
    "                segment_fraction = (target - segment_start) / (segment_end - segment_start)\n",
    "                path[i] = fine_path[prev_idx] + segment_fraction * (fine_path[idx] - fine_path[prev_idx])\n",
    "                \n",
    "        # Create a new chain for the linker\n",
    "        linker_chain = Chain.Chain(\"L\")  # 'L' for linker\n",
    "        prev_c = start_res['C'].get_coord()\n",
    "        prev_ca = start_ca\n",
    "        for i in range(num_residues):\n",
    "            # Calculate tangent for better backbone placement\n",
    "            if i < len(path) - 1:\n",
    "                tangent = path[i+1] - path[i]\n",
    "            else:\n",
    "                tangent = end_direction\n",
    "            tangent = tangent / np.linalg.norm(tangent)\n",
    "                    \n",
    "            res_atoms = self._generate_backbone_atoms_with_direction(\n",
    "                prev_c, prev_ca, path[i], tangent\n",
    "            )\n",
    "            prev_c = res_atoms['C']\n",
    "            prev_ca = res_atoms['CA']\n",
    "            \n",
    "            residue = Residue.Residue((' ', i+1, ' ') , \"GLY\", \"\")\n",
    "            \n",
    "            # Add atoms to residue\n",
    "            for atom_name, position in res_atoms.items():\n",
    "                atom_id = atom_name\n",
    "                element = atom_name[0]  # First letter of atom name\n",
    "                atom = Atom.Atom(atom_id, Vector(position), 0.0, 1.0, \" \", atom_id, element)\n",
    "                residue.add(atom)\n",
    "            \n",
    "            # Add residue to chain\n",
    "            linker_chain.add(residue)\n",
    "\n",
    "        return linker_chain\n",
    "         \n",
    "        \n",
    "    \n",
    "    def _evaluate_bezier(self, control_points, t):\n",
    "        \"\"\"Evaluate a cubic Bezier curve at parameter t.\"\"\"\n",
    "        p0, p1, p2, p3 = control_points\n",
    "        return (\n",
    "            (1-t)**3 * p0 + \n",
    "            3*(1-t)**2 * t * p1 + \n",
    "            3*(1-t) * t**2 * p2 + \n",
    "            t**3 * p3\n",
    "        )\n",
    "\n",
    "    def _calculate_path_length(self, control_points, num_points=100):\n",
    "        \"\"\"Calculate the total length of the Bezier curve.\"\"\"\n",
    "        t = np.linspace(0, 1, num_points)\n",
    "        points = np.array([self._evaluate_bezier(control_points, ti) for ti in t])\n",
    "        \n",
    "        # Calculate total length as sum of segments\n",
    "        segments = np.diff(points, axis=0)\n",
    "        lengths = np.sqrt(np.sum(segments**2, axis=1))\n",
    "        return np.sum(lengths) \n",
    "    \n",
    "class Segment:\n",
    "    def get_named_atom(self,residue, atom_name):\n",
    "        \"\"\"\n",
    "        Retrieves a specific atom from a residue.\n",
    "\n",
    "        Args:\n",
    "            residue (Bio.PDB.Residue.Residue): The residue to search within.\n",
    "            atom_name (str): The name of the atom to find (e.g., 'N', 'CA', 'C', 'O').\n",
    "\n",
    "        Returns:\n",
    "            Bio.PDB.Atom.Atom or None: The Atom object if found, otherwise None.\n",
    "        \"\"\"\n",
    "        if atom_name in residue:\n",
    "            return residue[atom_name]\n",
    "        return None\n",
    "    \n",
    "    def _calculate_residue_direction(self, residue):\n",
    "        \"\"\"Calculate the direction vector of a residue's backbone.\"\"\"\n",
    "        ca_pos = residue['CA'].get_coord()\n",
    "        if 'C' in residue:\n",
    "            c_pos = residue['C'].get_coord()\n",
    "            direction = c_pos - ca_pos\n",
    "        else:\n",
    "            n_pos = residue['N'].get_coord()\n",
    "            direction = ca_pos - n_pos\n",
    "        return direction / np.linalg.norm(direction)\n",
    "\n",
    "    \"\"\"Represents a contiguous segment of residues. multiple segments can be made from 1 chain\"\"\"\n",
    "    def __init__(self, residues, original_chain_id, segment_idx_in_chain):\n",
    "        if not residues:\n",
    "            raise ValueError(\"Segment cannot be empty\")\n",
    "        self.residues = list(residues) \n",
    "        self.original_chain_id = original_chain_id\n",
    "        \n",
    "        first_res_id_str = f\"{residues[0].id[0].strip()}{residues[0].id[1]}{residues[0].id[2].strip()}\"\n",
    "        last_res_id_str = f\"{residues[-1].id[0].strip()}{residues[-1].id[1]}{residues[-1].id[2].strip()}\"\n",
    "        self.id = f\"Seg-{original_chain_id}-{segment_idx_in_chain}({first_res_id_str}_to_{last_res_id_str})\"\n",
    "\n",
    "        self.n_res = self.residues[0]\n",
    "        self.c_res = self.residues[-1]\n",
    "\n",
    "        self.n_atom = self. get_named_atom(self.n_res, 'N')\n",
    "        self.c_atom =  self.get_named_atom(self.c_res, 'C')\n",
    "\n",
    "        if self.n_atom is None:\n",
    "            raise ValueError(f\"Segment {self.id} missing N-terminal atom for residue {self.n_res.id}.\")\n",
    "        if self.c_atom is None:\n",
    "            raise ValueError(f\"Segment {self.id} missing C-terminal atom for residue {self.c_res.id}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7606850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 18 segments in total.\n",
      "Found 10 chains\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 265\u001b[0m\n\u001b[0;32m    262\u001b[0m chainStich \u001b[38;5;241m=\u001b[39m    ChainStich(structure[\u001b[38;5;241m0\u001b[39m], excluded_chains\u001b[38;5;241m=\u001b[39m[ ], connection_threshold_Ang\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)    \n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m#chainStich.displaySegments()\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m \u001b[43mchainStich\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConnectClosest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxDistance_Ang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[35], line 244\u001b[0m, in \u001b[0;36mChainStich.ConnectClosest\u001b[1;34m(self, maxDistance_Ang)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chain_segments \u001b[38;5;129;01min\u001b[39;00m chains:\n\u001b[0;32m    243\u001b[0m     chain_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mchr\u001b[39m(chain_id_counter)\n\u001b[1;32m--> 244\u001b[0m     new_Chain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnectChains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain_segments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegments_to_connect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[43mchain_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     connected_model\u001b[38;5;241m.\u001b[39madd(new_Chain)\n\u001b[0;32m    246\u001b[0m     chain_id_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[35], line 186\u001b[0m, in \u001b[0;36mChainStich.connectChains\u001b[1;34m(self, chain_segments, segments_to_connect, chain_id)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m residues:\n\u001b[0;32m    185\u001b[0m     newRes \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 186\u001b[0m     newRes\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Reset residue ID\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     new_chain\u001b[38;5;241m.\u001b[39madd(newRes)\n\u001b[0;32m    189\u001b[0m linker \u001b[38;5;241m=\u001b[39m PolyGLinker()\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "class ChainStich:\n",
    "    def __init__(self, model, excluded_chains=None,connection_threshold_Ang= 10 ):\n",
    "        \"\"\"\n",
    "        Initialize linker for connecting helix chains.\n",
    "        \n",
    "        Args:\n",
    "            model: BioPython Model object containing the helices\n",
    "            excluded_chains: List of chain IDs to exclude (e.g., hemes)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.excluded_chains = excluded_chains or []\n",
    "        self.chain_ends = {}  # Store terminal residues for each chain\n",
    "        self.connections = []  # Store pairs of chain ends to connect\n",
    "        \n",
    "        \n",
    "        \n",
    "        #\n",
    "        # PEPTIDE_BOND_THRESHOLD: Distance (Angstroms) between C of res(i) and N of res(i+1)\n",
    "        # to be considered a broken peptide bond (i.e., a new segment starts).\n",
    "        self.PEPTIDE_BOND_THRESHOLD = 2.0  # Angstroms\n",
    "\n",
    "        # CONNECTION_THRESHOLD: Maximum distance (Angstroms) between terminal atoms\n",
    "        # of segments to consider them for connection.\n",
    "        self.CONNECTION_THRESHOLD = connection_threshold_Ang # Angstroms\n",
    "        \n",
    "        # Initialize structure\n",
    "        self.SegmentChains()\n",
    "        \n",
    "    def displaySegments(self):\n",
    "        \"\"\"\n",
    "        Displays each segment as a ribbon with a different color using py3Dmol.\n",
    "        Creates temporary chains from segments and renders the structure.\n",
    "        \"\"\"\n",
    "        # Create a new structure for visualization\n",
    "        struct = Structure.Structure(\"segmented\")\n",
    "        model = Model.Model(0)\n",
    "        struct.add(model)\n",
    "        \n",
    "        # Generate a list of distinct colors\n",
    "        colors = plt.cm.rainbow(np.linspace(0, 1, len(self.segments)))\n",
    "        colors = [f'rgb({int(r*255)},{int(g*255)},{int(b*255)})' for r, g, b, _ in colors]\n",
    "        \n",
    "        # Create chains from segments\n",
    "        for i, segment in enumerate(self.segments):\n",
    "            chain_id = chr(65 + (i % 26))  # A-Z (looping if needed)\n",
    "            chain = Chain.Chain(chain_id)\n",
    "            \n",
    "            for residue in segment.residues:\n",
    "                # Create a deep copy of the residue\n",
    "                new_res = Residue.Residue(residue.id, residue.resname, residue.segid)\n",
    "                for atom in residue:\n",
    "                    new_atom = Atom.Atom(atom.name, atom.coord, atom.bfactor, \n",
    "                                         atom.occupancy, atom.altloc, atom.fullname, \n",
    "                                         atom.serial_number, atom.element)\n",
    "                    new_res.add(new_atom)\n",
    "                chain.add(new_res)\n",
    "            model.add(chain)\n",
    "        \n",
    "        # Save structure to temporary PDB file\n",
    "        io = PDBIO()\n",
    "        io.set_structure(struct)\n",
    "        temp_pdb = \"temp_segmented.pdb\"\n",
    "        io.save(temp_pdb)\n",
    "        \n",
    "        # Visualize with py3Dmol\n",
    "        view = py3Dmol.view(width=800, height=600)\n",
    "        view.addModel(open(temp_pdb, 'r').read(), 'pdb')\n",
    "        \n",
    "        # Color chains based on segment\n",
    "        for i, segment in enumerate(self.segments):\n",
    "            chain_id = chr(65 + (i % 26))\n",
    "            view.setStyle({'chain': chain_id}, {'cartoon': {'color': colors[i]}})\n",
    "        \n",
    "        view.zoomTo()\n",
    "        view.setBackgroundColor('white')\n",
    "        return view.show()\n",
    "        \n",
    "    def SegmentChains(self):\n",
    " \n",
    "        all_segments = []\n",
    "        \n",
    "        for chain in self.model:\n",
    "            residues_in_chain = [res for res in chain.get_residues() if PDB.is_aa(res, standard=True) or res.id[0] != ' ']\n",
    "            if not residues_in_chain:\n",
    "                continue\n",
    "\n",
    "            current_segment_residues = []\n",
    "            segment_counter_for_chain = 0\n",
    "            for i, res in enumerate(residues_in_chain):\n",
    "                if not current_segment_residues:\n",
    "                    current_segment_residues.append(res)\n",
    "                else:\n",
    "                    prev_res = current_segment_residues[-1]\n",
    "                    if 'C' in prev_res and 'N' in res:\n",
    "                        dist = np.linalg.norm(prev_res['C'].get_coord() - res['N'].get_coord())\n",
    "                        if dist > self.PEPTIDE_BOND_THRESHOLD:\n",
    "                            all_segments.append(Segment(current_segment_residues, chain.id, segment_counter_for_chain))\n",
    "                            segment_counter_for_chain += 1\n",
    "                            current_segment_residues = [res]\n",
    "                        else:\n",
    "                            current_segment_residues.append(res)\n",
    "                    else: \n",
    "                        all_segments.append(Segment(current_segment_residues, chain.id, segment_counter_for_chain))\n",
    "                        segment_counter_for_chain += 1\n",
    "                        current_segment_residues = [res]\n",
    "            \n",
    "            if current_segment_residues:\n",
    "                all_segments.append(Segment(current_segment_residues, chain.id, segment_counter_for_chain))\n",
    "\n",
    "        if not all_segments:\n",
    "            print(\"No valid segments found in the PDB file.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Identified {len(all_segments)} segments in total.\")       \n",
    "        self.segments = all_segments \n",
    "        \n",
    "    \n",
    "    def getConnections(self,segments_to_connect, maxDistance_Ang ):\n",
    "         # Find all potential connections between segments\n",
    "         \n",
    "        edges = []\n",
    "        # Track which segments can form connections\n",
    "        for i, seg1 in enumerate(segments_to_connect):\n",
    "            bestDist  = np.inf\n",
    "            bestSeg2 = None\n",
    "            second_bestDist = np.inf\n",
    "            second_bestSeg2 = None\n",
    "            for j in range(i+1, len(segments_to_connect)):\n",
    "                # Calculate distance between C-term of seg1 and N-term of seg2\n",
    "                seg2 = segments_to_connect[j]\n",
    "                c_n_distance = np.linalg.norm(\n",
    "                    seg1.c_atom.get_coord() - seg2.n_atom.get_coord()\n",
    "                )\n",
    "                \n",
    "                # If distance is within threshold, add to potential connections\n",
    "                if c_n_distance <= maxDistance_Ang and c_n_distance < bestDist:\n",
    "                        bestDist = c_n_distance\n",
    "                        second_bestSeg2 = bestSeg2\n",
    "                        second_bestDist = bestDist\n",
    "                        bestSeg2 = j\n",
    "            \n",
    "            if bestSeg2 is not None:\n",
    "                edges.append((i, bestSeg2, {\"dist\":bestDist}) )\n",
    "            if second_bestSeg2 is not None:\n",
    "                edges.append((i, second_bestSeg2, {\"dist\":second_bestDist}) )\n",
    "                    \n",
    "        return edges\n",
    "    \n",
    "    \n",
    "    def find_optimal_connections(self, edges, segments):\n",
    "        \"\"\"Find the permutation that maximizes the number of connected segments\"\"\"\n",
    "        # Create a graph from the edges\n",
    "        remaining_segments = set(range(len(segments)))\n",
    "        longestPaths = []\n",
    "        while len(remaining_segments) > 1:\n",
    "            # Create a directed graph from the edges\n",
    "            G = nx.DiGraph()\n",
    "            G.add_edges_from(edges)\n",
    "            \n",
    "            # Find the largest connected component\n",
    "            longestPath =nx.dag_longest_path(G, weight=\"dist\")\n",
    "            if len(longestPath) ==0:\n",
    "                break\n",
    "            longestPaths.append(longestPath )\n",
    "            \n",
    "            #remove the segments in longest path from remaining segments, and edges\n",
    "            for i in longestPath:\n",
    "                remaining_segments.remove(i)\n",
    "                edges = [edge for edge in edges if edge[0] != i and edge[1] != i]\n",
    "                  \n",
    "        #add the remaining segments as singletons\n",
    "        for i in remaining_segments:\n",
    "            longestPaths.append([i])\n",
    "        return longestPaths\n",
    "       \n",
    "    \n",
    "    def connectChains(self, chain_segments, segments_to_connect,    chain_id):\n",
    "        \"\"\"Connect segments in a chain using PolyGLinker.\"\"\"\n",
    "        # Create a new chain for the connected segments\n",
    "        new_chain = Chain.Chain(chain_id)\n",
    "        \n",
    "        for i in range(len(chain_segments) - 1):\n",
    "            residues = segments_to_connect[chain_segments[i]].residues[-1]\n",
    "            for res in residues:\n",
    "                newRes = res.copy()\n",
    "                newRes.id = (' ', res.id[1], ' ')  # Reset residue ID\n",
    "                new_chain.add(newRes)\n",
    "                \n",
    "            linker = PolyGLinker()\n",
    "            linkResidues = linker.generate_linker(\n",
    "                segments_to_connect[chain_segments[i]],\n",
    "                segments_to_connect[chain_segments[i + 1]]\n",
    "            )\n",
    "            for res in linkResidues:\n",
    "                newRes = res.copy()\n",
    "                newRes.id = (' ', res.id[1], ' ')  # Reset residue ID\n",
    "                new_chain.add(newRes)\n",
    "        \n",
    "        # Add the last segment to the new chain\n",
    "        last_segment = segments_to_connect[chain_segments[-1]].residues\n",
    "        for res in last_segment:\n",
    "            newRes = res.copy()\n",
    "            newRes.id = (' ', res.id[1], ' ')  # Reset residue ID\n",
    "            new_chain.add(newRes)\n",
    "        return new_chain\n",
    "        \n",
    "    def ConnectClosest(self, maxDistance_Ang=10):\n",
    "        \"\"\"\n",
    "        Connect segments with the closest ends, respecting protein chain directionality.\n",
    "        Uses PolyGLinker to generate connecting residues between segments.\n",
    "        \n",
    "        Args:\n",
    "            maxDistance_Ang: Maximum distance in Angstroms to consider for connections\n",
    "        \n",
    "        Returns:\n",
    "            A new PDB structure with connected segments\n",
    "        \"\"\"\n",
    "        # Create a copy of the segments to avoid modifying the originals\n",
    "        segments_to_connect = self.segments.copy()\n",
    "        if not segments_to_connect:\n",
    "            print(\"No segments to connect.\")\n",
    "            return None\n",
    "        \n",
    "        # Create a new structure for the connected protein\n",
    "        connected_structure = Structure.Structure(\"connected_protein\")\n",
    "        connected_model = Model.Model(0)\n",
    "        connected_structure.add(connected_model)\n",
    "       \n",
    "        potential_connections = self.getConnections(segments_to_connect, maxDistance_Ang)\n",
    "\n",
    "        # Get the optimal connections\n",
    "        chains = self.find_optimal_connections(potential_connections, segments_to_connect)\n",
    "\n",
    "        print(f\"Found {len(chains)} chains\")\n",
    "\n",
    "        # Create a linker for generating connecting residues\n",
    "        \n",
    "\n",
    "        # Organize segments by chain IDs and add them to the new structure\n",
    "        chain_id_counter = 65  # Start with 'A'\n",
    "        \n",
    "        for chain_segments in chains:\n",
    "            chain_id = chr(chain_id_counter)\n",
    "            new_Chain = self.connectChains(chain_segments, segments_to_connect,    chain_id)\n",
    "            connected_model.add(new_Chain)\n",
    "            chain_id_counter += 1\n",
    "        \n",
    "        return connected_model\n",
    "    \n",
    "       \n",
    "       \n",
    "input_pdb_path=r'C:\\Users\\bashc\\Desktop\\working\\ssBinding\\working8.pdb'        \n",
    "parser = PDB.PDBParser(QUIET=True)\n",
    "try:\n",
    "    structure = parser.get_structure('protein', input_pdb_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input PDB file not found at {input_pdb_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing PDB file {input_pdb_path}: {e}\")\n",
    "\n",
    "        \n",
    "chainStich =    ChainStich(structure[0], excluded_chains=[ ], connection_threshold_Ang= 10)    \n",
    "\n",
    "#chainStich.displaySegments()\n",
    "chainStich.ConnectClosest(maxDistance_Ang=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70519cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c25c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00213f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure aligned and saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['N', 'E', 'H', 'K', 'Z', 'Q']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    def _find_closest_connections(self):\n",
    "        \"\"\"Find closest chain ends to connect.\"\"\"\n",
    "        chain_ids = list(self.chain_ends.keys())\n",
    "        \n",
    "        for i, chain1 in enumerate(chain_ids):\n",
    "            distances = []\n",
    "            for chain2 in chain_ids[i+1:]:  # Only look at chains we haven't considered yet\n",
    "                end_carbon = self.chain_ends[chain1]['C']['C'].get_coord()\n",
    "                start_n = self.chain_ends[chain2]['N']['N'].get_coord()\n",
    "                \n",
    "                distances.append({\n",
    "                    'c2': chain2,\n",
    "                    'distance': np.linalg.norm(end_carbon - start_n)\n",
    "                })\n",
    "            \n",
    "            if distances:  # Only add if we found valid connections\n",
    "                best_connection = min(distances, key=lambda x: x['distance'])\n",
    "                self.connections.append({\n",
    "                    'chain1': chain1,\n",
    "                    'chain2': best_connection['c2'],\n",
    "                    'distance': best_connection['distance']\n",
    "                })\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def connect_chains(self):\n",
    "        \"\"\"Connect all identified chain pairs with linkers.\"\"\"\n",
    "        connection=  min(self.connections, key=lambda x: x['distance'])\n",
    "        if connection['distance'] > 25:\n",
    "            print('too far',connection['distance'])\n",
    "            return False\n",
    "        backbone_atoms = self.generate_linker(connection)\n",
    "        \n",
    "        # Get the chains to connect\n",
    "        chain1_id = connection['chain1']\n",
    "        chain2_id = connection['chain2']\n",
    "        \n",
    "        # Add linker residues to chain1\n",
    "        last_res_id = max(int(res.id[1]) for res in self.model[chain1_id])\n",
    "        \n",
    "        # Add linker residues\n",
    "        for i, atoms in enumerate(backbone_atoms):\n",
    "            new_res_id = last_res_id + i + 1\n",
    "            new_res = Residue.Residue((' ', new_res_id, ' '), 'GLY', '')\n",
    "            \n",
    "            for atom_name, coord in atoms.items():\n",
    "                new_atom = Atom.Atom(\n",
    "                    name=atom_name,\n",
    "                    coord=coord,\n",
    "                    bfactor=20.0,\n",
    "                    occupancy=1.0,\n",
    "                    altloc=' ',\n",
    "                    fullname=atom_name,\n",
    "                    serial_number=None,\n",
    "                    element=atom_name[0]\n",
    "                )\n",
    "                new_res.add(new_atom)\n",
    "            \n",
    "            self.model[chain1_id].add(new_res)\n",
    "        \n",
    "        # Move residues from chain2 to chain1\n",
    "        residues_to_move = list(self.model[chain2_id].get_residues())\n",
    "        chain =self.model[chain1_id]\n",
    "        new_res_id=max([max(int(res.id[1]) for res in chain), max(int(res.id[1]) for res in residues_to_move)])\n",
    "        for res in residues_to_move:\n",
    "            try:\n",
    "                new_res_id +=1\n",
    "                res.id = (' ', new_res_id, ' ')\n",
    "                chain.add(res)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Error adding residue\")\n",
    "        \n",
    "        # Remove chain2\n",
    "        self.model.detach_child(chain2_id)\n",
    "        print(chain1_id,chain2_id)\n",
    "        return True\n",
    "         \n",
    "\n",
    "aligner = HemeHelixAligner(\"double_heme.pdb\")\n",
    "aligner.align_all()\n",
    "aligner.save_structure('test.pdb')\n",
    "print(\"Structure aligned and saved.\")\n",
    "\n",
    "model =aligner.model\n",
    "# Initialize the manipulator with your model\n",
    "manipulator = HelixManipulator(model)\n",
    "\n",
    "# Align helices with z-axis\n",
    "manipulator.align_to_z()\n",
    "\n",
    "# Rotate helices (e.g., 30 degrees)\n",
    "angle = 10\n",
    "manipulator.rotate_helices(angle)\n",
    "manipulator.create_packed_copies(angle)\n",
    "\n",
    "\n",
    "io = PDBIO()\n",
    "io.set_structure(model)\n",
    "io.save(\"target-complex.pdb\")\n",
    "\n",
    "heme_chains = []\n",
    "for chain in model:\n",
    "    for residue in chain:\n",
    "        if residue.get_resname() == \"HEM\":\n",
    "            heme_chains.append(chain.id)\n",
    "            break\n",
    "        \n",
    "heme_chains        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b824b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 18 segments in total.\n",
      "Best primary chain will connect 17 segments.\n",
      "  Main chain: adding 5 glycines between ...Seg-W-5(205_to_216) and Seg-Z-4(146_to_162) (C-N dist: 23.57 A)\n",
      "  Main chain: adding 4 glycines between ...Seg-Z-4(146_to_162) and Seg-Z-2(45_to_67) (C-N dist: 18.71 A)\n",
      "  Main chain: adding 1 glycines between ...Seg-Z-2(45_to_67) and Seg-Z-0(5_to_5) (C-N dist: 7.71 A)\n",
      "  Main chain: adding 2 glycines between ...Seg-Z-1(6_to_37) and Seg-C-0(20_to_44) (C-N dist: 10.30 A)\n",
      "  Main chain: adding 2 glycines between ...Seg-C-0(20_to_44) and Seg-A-0(16_to_44) (C-N dist: 11.21 A)\n",
      "  Main chain: adding 1 glycines between ...Seg-A-0(16_to_44) and Seg-W-6(229_to_256) (C-N dist: 9.45 A)\n",
      "  Main chain: adding 1 glycines between ...Seg-W-6(229_to_256) and Seg-W-7(259_to_259) (C-N dist: 8.08 A)\n",
      "  Main chain: adding 2 glycines between ...Seg-W-8(260_to_276) and Seg-W-4(159_to_188) (C-N dist: 12.12 A)\n",
      "  Main chain: adding 2 glycines between ...Seg-W-3(131_to_155) and Seg-W-1(60_to_75) (C-N dist: 10.84 A)\n",
      "  Main chain: adding 1 glycines between ...Seg-W-1(60_to_75) and Seg-W-2(81_to_110) (C-N dist: 8.81 A)\n",
      "  Main chain: adding 3 glycines between ...Seg-W-2(81_to_110) and Seg-W-0(1_to_49) (C-N dist: 14.59 A)\n",
      "  Main chain: adding 6 glycines between ...Seg-W-0(1_to_49) and Seg-Z-5(174_to_273) (C-N dist: 24.73 A)\n",
      "  Unused segment Seg-Z-3(71_to_117) from original chain Z forms a separate chain.\n",
      "Outputting Chain A with 493 residues.\n",
      "Outputting Chain B with 47 residues.\n",
      "Successfully processed segments. Output saved to C:\\Users\\bashc\\Desktop\\working\\ssBinding\\connected.pdb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def bernstein_polynomial(t, n, i):\n",
    "    \"\"\"Bernstein polynomial for Bezier curve calculation.\"\"\"\n",
    "    return comb(n, i) * (t ** i) * ((1 - t) ** (n - i))\n",
    "\n",
    "def bezier_curve(control_points, num_points=100):\n",
    "    \"\"\"\n",
    "    Generate points along a Bezier curve defined by control points.\n",
    "    \n",
    "    Args:\n",
    "        control_points: List of 3D coordinates (numpy arrays)\n",
    "        num_points: Number of points to generate along the curve\n",
    "    \n",
    "    Returns:\n",
    "        List of coordinates along the curve\n",
    "    \"\"\"\n",
    "    n = len(control_points) - 1\n",
    "    curve_points = []\n",
    "    \n",
    "    for t in np.linspace(0, 1, num_points):\n",
    "        point = np.zeros(3)\n",
    "        for i, cp in enumerate(control_points):\n",
    "            point += bernstein_polynomial(t, n, i) * cp\n",
    "        curve_points.append(point)\n",
    "    \n",
    "    return curve_points\n",
    "\n",
    "def create_glycine_residue(res_id, position, prev_c_pos=None, next_n_pos=None):\n",
    "    \"\"\"\n",
    "    Create a glycine residue with coordinates based on the given position.\n",
    "    Adjusts N and C atoms to form peptide bonds of PEPTIDE_BOND_LENGTH.\n",
    "    Places O atom using standard geometry relative to N, CA, C of the glycine.\n",
    "\n",
    "    Args:\n",
    "        res_id: Residue ID tuple (hetflag, resnum, icode)\n",
    "        position: 3D coordinates for CA atom (numpy array)\n",
    "        prev_c_pos: Position of C atom from previous residue for N-terminal connection\n",
    "        next_n_pos: Position of N atom from next residue for C-terminal connection\n",
    "\n",
    "    Returns:\n",
    "        Bio.PDB.Residue with proper glycine geometry\n",
    "    \"\"\"\n",
    "    res = Residue.Residue(res_id, \"GLY\", \" \")\n",
    "    ca_coord = np.array(position)\n",
    "\n",
    "    # Ideal Glycine coordinates relative to CA at origin (N-CA-C plane in XY)\n",
    "    n_ideal_offset_from_ca = np.array([-0.589, -1.354, 0.0]) \n",
    "    c_ideal_offset_from_ca = np.array([1.523, 0.0, 0.0])\n",
    "\n",
    "    n_coord = ca_coord + n_ideal_offset_from_ca\n",
    "    c_coord = ca_coord + c_ideal_offset_from_ca\n",
    "\n",
    "    if prev_c_pos is not None:\n",
    "        prev_c_coord = np.array(prev_c_pos)\n",
    "        vec_prevC_to_glyCA = ca_coord - prev_c_coord\n",
    "        dist_prevC_to_glyCA = np.linalg.norm(vec_prevC_to_glyCA)\n",
    "        if dist_prevC_to_glyCA > 1e-3: \n",
    "            dir_prevC_to_glyCA = vec_prevC_to_glyCA / dist_prevC_to_glyCA\n",
    "            n_coord = prev_c_coord + dir_prevC_to_glyCA * PEPTIDE_BOND_LENGTH\n",
    "\n",
    "    if next_n_pos is not None:\n",
    "        next_n_coord = np.array(next_n_pos)\n",
    "        vec_glyCA_to_nextN = next_n_coord - ca_coord\n",
    "        dist_glyCA_to_nextN = np.linalg.norm(vec_glyCA_to_nextN)\n",
    "        if dist_glyCA_to_nextN > 1e-3: \n",
    "            dir_glyCA_to_nextN = vec_glyCA_to_nextN / dist_glyCA_to_nextN\n",
    "            c_coord = next_n_coord - dir_glyCA_to_nextN * PEPTIDE_BOND_LENGTH\n",
    "\n",
    "    vec_ca_c = c_coord - ca_coord\n",
    "    vec_ca_n = n_coord - ca_coord \n",
    "\n",
    "    norm_vec_ca_c = np.linalg.norm(vec_ca_c)\n",
    "    norm_vec_ca_n = np.linalg.norm(vec_ca_n)\n",
    "\n",
    "    if norm_vec_ca_c < 1e-3 or norm_vec_ca_n < 1e-3:\n",
    "        o_default_offset_from_c = np.array([0.624, 1.078, 0.0]) \n",
    "        o_coord = c_coord + o_default_offset_from_c \n",
    "    else:\n",
    "        u_ca_c = vec_ca_c / norm_vec_ca_c \n",
    "        u_ca_n = vec_ca_n / norm_vec_ca_n \n",
    "\n",
    "        plane_normal = np.cross(u_ca_n, u_ca_c)\n",
    "        norm_plane_normal = np.linalg.norm(plane_normal)\n",
    "\n",
    "        if norm_plane_normal < 1e-3: \n",
    "            if abs(u_ca_c[0]) > 0.9: arbitrary_perp_ref = np.array([0.0, 1.0, 0.0])\n",
    "            else: arbitrary_perp_ref = np.array([1.0, 0.0, 0.0])\n",
    "            plane_normal = np.cross(u_ca_c, arbitrary_perp_ref)\n",
    "            if np.linalg.norm(plane_normal) < 1e-3: \n",
    "                 plane_normal = np.cross(u_ca_c, np.array([0.0,0.0,1.0]))\n",
    "            plane_normal /= np.linalg.norm(plane_normal)\n",
    "\n",
    "        m_vec = np.cross(plane_normal, u_ca_c)\n",
    "        m_vec = m_vec / np.linalg.norm(m_vec)\n",
    "        \n",
    "        if np.dot(m_vec, u_ca_n - u_ca_c * np.dot(u_ca_n, u_ca_c)) < 0:\n",
    "            m_vec = -m_vec\n",
    "            \n",
    "        C_O_BOND_LENGTH = 1.23 \n",
    "        ANGLE_CA_C_O = np.radians(120.8) \n",
    "\n",
    "        o_coord_comp_along_cca = C_O_BOND_LENGTH * np.cos(ANGLE_CA_C_O)\n",
    "        o_coord_comp_along_mvec = C_O_BOND_LENGTH * np.sin(ANGLE_CA_C_O)\n",
    "        \n",
    "        o_coord = c_coord + o_coord_comp_along_cca * (-u_ca_c) + o_coord_comp_along_mvec * m_vec\n",
    "\n",
    "    n_atom = Atom.Atom('N', n_coord, 0.0, 1.0, ' ', ' N  ', 0, 'N')\n",
    "    ca_atom = Atom.Atom('CA', ca_coord, 0.0, 1.0, ' ', ' CA ', 0, 'C')\n",
    "    c_atom = Atom.Atom('C', c_coord, 0.0, 1.0, ' ', ' C  ', 0, 'C')\n",
    "    o_atom = Atom.Atom('O', o_coord, 0.0, 1.0, ' ', ' O  ', 0, 'O')\n",
    "    \n",
    "    res.add(n_atom)\n",
    "    res.add(ca_atom)\n",
    "    res.add(c_atom)\n",
    "    res.add(o_atom)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def connect_broken_chains(input_pdb_path, output_pdb_path):\n",
    "    \"\"\"\n",
    "    Loads a PDB file, identifies all segments, determines the optimal way to connect\n",
    "    them into a primary long chain, and connects remaining segments into secondary chains.\n",
    "    Fills gaps with glycine residues. Outputs all resulting chains.\n",
    "    \"\"\"\n",
    "    parser = PDB.PDBParser(QUIET=True)\n",
    "    try:\n",
    "        structure = parser.get_structure('protein', input_pdb_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input PDB file not found at {input_pdb_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing PDB file {input_pdb_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    \n",
    "\n",
    "    # --- 3. Find the best single chain by trying all possible start segments ---\n",
    "    best_connection_run = {\n",
    "        \"initial_segment_index\": -1,\n",
    "        \"connected_segments_ordered\": [], \n",
    "        \"num_original_segments\": 0\n",
    "    }\n",
    "\n",
    "    for i, initial_seg in enumerate(all_segments):\n",
    "        current_merged_chain_segments = [initial_seg]\n",
    "        remaining_for_this_run = [s for idx, s in enumerate(all_segments) if idx != i]\n",
    "        \n",
    "        chain_n_end_atom = initial_seg.n_atom \n",
    "        chain_c_end_atom = initial_seg.c_atom\n",
    "\n",
    "        while remaining_for_this_run:\n",
    "            best_append_candidate = None \n",
    "            min_dist_append = float('inf')\n",
    "            best_prepend_candidate = None\n",
    "            min_dist_prepend = float('inf')\n",
    "\n",
    "            chain_c_coord = chain_c_end_atom.get_coord()\n",
    "            chain_n_coord = chain_n_end_atom.get_coord()\n",
    "\n",
    "            for j, seg_candidate in enumerate(remaining_for_this_run):\n",
    "                dist_c_to_n = np.linalg.norm(chain_c_coord - seg_candidate.n_atom.get_coord())\n",
    "                if dist_c_to_n < min_dist_append:\n",
    "                    min_dist_append = dist_c_to_n\n",
    "                    best_append_candidate = (j, seg_candidate, dist_c_to_n)\n",
    "\n",
    "                dist_n_to_c = np.linalg.norm(chain_n_coord - seg_candidate.c_atom.get_coord())\n",
    "                if dist_n_to_c < min_dist_prepend:\n",
    "                    min_dist_prepend = dist_n_to_c\n",
    "                    best_prepend_candidate = (j, seg_candidate, dist_n_to_c)\n",
    "            \n",
    "            added_in_iteration = False\n",
    "            choice_made = None\n",
    "            \n",
    "            can_append = best_append_candidate and best_append_candidate[2] < CONNECTION_THRESHOLD\n",
    "            can_prepend = best_prepend_candidate and best_prepend_candidate[2] < CONNECTION_THRESHOLD\n",
    "\n",
    "            if can_append and can_prepend:\n",
    "                choice_made = \"append\" if best_append_candidate[2] <= best_prepend_candidate[2] else \"prepend\"\n",
    "            elif can_append:\n",
    "                choice_made = \"append\"\n",
    "            elif can_prepend:\n",
    "                choice_made = \"prepend\"\n",
    "\n",
    "            if choice_made == \"append\":\n",
    "                idx_rem, seg_to_add, _ = best_append_candidate\n",
    "                current_merged_chain_segments.append(seg_to_add)\n",
    "                chain_c_end_atom = seg_to_add.c_atom \n",
    "                remaining_for_this_run.pop(idx_rem)\n",
    "                added_in_iteration = True\n",
    "            elif choice_made == \"prepend\":\n",
    "                idx_rem, seg_to_add, _ = best_prepend_candidate\n",
    "                current_merged_chain_segments.insert(0, seg_to_add)\n",
    "                chain_n_end_atom = seg_to_add.n_atom \n",
    "                remaining_for_this_run.pop(idx_rem)\n",
    "                added_in_iteration = True\n",
    "            \n",
    "            if not added_in_iteration:\n",
    "                break \n",
    "\n",
    "        if len(current_merged_chain_segments) > best_connection_run[\"num_original_segments\"]:\n",
    "            best_connection_run[\"initial_segment_index\"] = i\n",
    "            best_connection_run[\"connected_segments_ordered\"] = list(current_merged_chain_segments)\n",
    "            best_connection_run[\"num_original_segments\"] = len(current_merged_chain_segments)\n",
    "\n",
    "    # --- 4. Build the primary chain ---\n",
    "    final_chains_residues = [] \n",
    "    used_segments_for_main_chain = set()\n",
    "    \n",
    "    max_res_num_in_pdb = 0\n",
    "    for seg_glob in all_segments:\n",
    "        for res_glob in seg_glob.residues:\n",
    "            if res_glob.id[1] > max_res_num_in_pdb:\n",
    "                max_res_num_in_pdb = res_glob.id[1]\n",
    "    temp_glycine_res_num_counter = max_res_num_in_pdb\n",
    "\n",
    "    if not best_connection_run[\"connected_segments_ordered\"]:\n",
    "        print(\"Warning: Could not form any primary connected chain.\")\n",
    "    else:\n",
    "        print(f\"Best primary chain will connect {best_connection_run['num_original_segments']} segments.\")\n",
    "        primary_chain_merged_residues = []\n",
    "        segments_for_main_chain = best_connection_run[\"connected_segments_ordered\"]\n",
    "        \n",
    "        primary_chain_merged_residues.extend(segments_for_main_chain[0].residues)\n",
    "        # The C-atom of the *last added residue* to primary_chain_merged_residues\n",
    "        current_c_atom_obj_main = get_terminal_atom(primary_chain_merged_residues[-1], 'C')\n",
    "        if not current_c_atom_obj_main: # Should not happen if segment is valid\n",
    "             raise ValueError(f\"Segment {segments_for_main_chain[0].id} has no C-terminal C atom in its last residue.\")\n",
    "\n",
    "\n",
    "        for i in range(1, len(segments_for_main_chain)):\n",
    "            prev_segment_in_main = segments_for_main_chain[i-1] # For context/CA\n",
    "            current_segment_to_add_main = segments_for_main_chain[i]\n",
    "\n",
    "            prev_c_for_glycine = current_c_atom_obj_main.get_coord()\n",
    "            next_n_for_glycine = current_segment_to_add_main.n_atom.get_coord()\n",
    "            dist_c_n = np.linalg.norm(prev_c_for_glycine - next_n_for_glycine)\n",
    "\n",
    "            added_glycines_main = []\n",
    "            if dist_c_n > PEPTIDE_BOND_THRESHOLD:\n",
    "                p0 = prev_c_for_glycine\n",
    "                p3 = next_n_for_glycine\n",
    "                ca_prev_res = primary_chain_merged_residues[-1] # Last residue of growing chain\n",
    "                ca_next_res = current_segment_to_add_main.residues[0] # First residue of next segment\n",
    "\n",
    "                if 'CA' in ca_prev_res and 'CA' in ca_next_res:\n",
    "                    ca_prev = ca_prev_res['CA'].get_coord()\n",
    "                    ca_next = ca_next_res['CA'].get_coord()\n",
    "                    v0 = p0 - ca_prev \n",
    "                    v3 = p3 - ca_next \n",
    "                    p1 = p0 + v0 * 0.5 \n",
    "                    p2 = p3 + v3 * 0.5 \n",
    "                else: \n",
    "                    mid_point = (p0 + p3) / 2.0\n",
    "                    p1 = p0 + (mid_point - p0) * 0.5\n",
    "                    p2 = p3 + (mid_point - p3) * 0.5\n",
    "                control_points = [p0, p1, p2, p3]\n",
    "\n",
    "                curve_length_approx = np.linalg.norm(p3 - p0) \n",
    "                num_glycines = max(0, int(round(curve_length_approx / CA_CA_DISTANCE)) -1)\n",
    "\n",
    "                if num_glycines > 0:\n",
    "                    print(f\"  Main chain: adding {num_glycines} glycines between ...{prev_segment_in_main.id} and {current_segment_to_add_main.id} (C-N dist: {dist_c_n:.2f} A)\")\n",
    "                    ca_p0 = ca_prev_res['CA'].get_coord() if 'CA' in ca_prev_res else p0\n",
    "                    ca_p3 = ca_next_res['CA'].get_coord() if 'CA' in ca_next_res else p3\n",
    "                    \n",
    "                    ca_v0 = ca_p0 - p0 \n",
    "                    ca_v3 = ca_p3 - p3\n",
    "\n",
    "                    ca_control_points = [ca_p0, ca_p0 + ca_v0 * 0.5, ca_p3 + ca_v3 * 0.5, ca_p3]\n",
    "                    if num_glycines == 1 and np.linalg.norm(ca_p0 - ca_p3) < CA_CA_DISTANCE * 1.5 :\n",
    "                         gly_ca_positions = [(ca_p0 + ca_p3)/2.0]\n",
    "                    else:\n",
    "                        gly_ca_curve = bezier_curve(ca_control_points, num_points=num_glycines + 2)\n",
    "                        gly_ca_positions = gly_ca_curve[1:-1]\n",
    "                    \n",
    "                    current_connection_c_coord_main = prev_c_for_glycine\n",
    "                    for k_gly, gly_ca_pos in enumerate(gly_ca_positions):\n",
    "                        temp_glycine_res_num_counter += 1\n",
    "                        prev_c_for_this_gly = current_connection_c_coord_main\n",
    "                        next_n_for_this_gly = next_n_for_glycine if k_gly == num_glycines - 1 else None\n",
    "                        gly_res = create_glycine_residue(\n",
    "                            (' ', temp_glycine_res_num_counter, ' '), gly_ca_pos,\n",
    "                            prev_c_pos=prev_c_for_this_gly, next_n_pos=next_n_for_this_gly\n",
    "                        )\n",
    "                        added_glycines_main.append(gly_res)\n",
    "                        current_connection_c_coord_main = gly_res['C'].get_coord()\n",
    "            \n",
    "            primary_chain_merged_residues.extend(added_glycines_main)\n",
    "            primary_chain_merged_residues.extend(current_segment_to_add_main.residues)\n",
    "            current_c_atom_obj_main = get_terminal_atom(primary_chain_merged_residues[-1], 'C')\n",
    "            if not current_c_atom_obj_main:\n",
    "                 raise ValueError(f\"Segment {current_segment_to_add_main.id} resulted in no C-terminal C atom after adding to main chain.\")\n",
    "\n",
    "        final_chains_residues.append(primary_chain_merged_residues)\n",
    "        used_segments_for_main_chain = set(segments_for_main_chain)\n",
    "\n",
    "    # --- 5. Process unused segments ---\n",
    "    all_segments_set = set(all_segments)\n",
    "    unused_segments_list = list(all_segments_set - used_segments_for_main_chain)\n",
    "    \n",
    "    unused_by_original_chain = {}\n",
    "    for seg in unused_segments_list:\n",
    "        unused_by_original_chain.setdefault(seg.original_chain_id, []).append(seg)\n",
    "\n",
    "    for chain_id_orig, seg_list_orig in unused_by_original_chain.items():\n",
    "        seg_list_orig.sort(key=lambda s: (s.residues[0].id[1], s.residues[0].id[2].strip())) # Sort by resnum then icode\n",
    "\n",
    "    processed_unused_segments = set()\n",
    "\n",
    "    for original_chain_id_of_unused, segments_from_one_orig_chain_initial in unused_by_original_chain.items():\n",
    "        \n",
    "        segments_to_process_in_group = [s for s in segments_from_one_orig_chain_initial if s not in processed_unused_segments]\n",
    "        \n",
    "        while segments_to_process_in_group:\n",
    "            if not segments_to_process_in_group: break\n",
    "\n",
    "            if len(segments_to_process_in_group) == 1:\n",
    "                seg_single = segments_to_process_in_group[0]\n",
    "                final_chains_residues.append(list(seg_single.residues))\n",
    "                processed_unused_segments.add(seg_single)\n",
    "                print(f\"  Unused segment {seg_single.id} from original chain {original_chain_id_of_unused} forms a separate chain.\")\n",
    "                segments_to_process_in_group.pop(0)\n",
    "                continue\n",
    "\n",
    "            best_internal_connection_run = { \"connected_segments_ordered\": [], \"num_original_segments\": 0 }\n",
    "\n",
    "            for i_start_internal, initial_seg_internal in enumerate(segments_to_process_in_group):\n",
    "                current_merged_internal = [initial_seg_internal]\n",
    "                remaining_internal = [s for idx, s in enumerate(segments_to_process_in_group) if idx != i_start_internal]\n",
    "                \n",
    "                chain_n_end_atom_internal = initial_seg_internal.n_atom\n",
    "                chain_c_end_atom_internal = initial_seg_internal.c_atom\n",
    "\n",
    "                while remaining_internal:\n",
    "                    best_append_internal = None; min_dist_app_int = float('inf')\n",
    "                    best_prepend_internal = None; min_dist_pre_int = float('inf')\n",
    "                    chain_c_coord_int = chain_c_end_atom_internal.get_coord()\n",
    "                    chain_n_coord_int = chain_n_end_atom_internal.get_coord()\n",
    "\n",
    "                    for j_int, seg_cand_int in enumerate(remaining_internal):\n",
    "                        dist_c_n_int = np.linalg.norm(chain_c_coord_int - seg_cand_int.n_atom.get_coord())\n",
    "                        if dist_c_n_int < min_dist_app_int:\n",
    "                            min_dist_app_int = dist_c_n_int\n",
    "                            best_append_internal = (j_int, seg_cand_int, dist_c_n_int)\n",
    "                        dist_n_c_int = np.linalg.norm(chain_n_coord_int - seg_cand_int.c_atom.get_coord())\n",
    "                        if dist_n_c_int < min_dist_pre_int:\n",
    "                            min_dist_pre_int = dist_n_c_int\n",
    "                            best_prepend_internal = (j_int, seg_cand_int, dist_n_c_int)\n",
    "                    \n",
    "                    added_in_iter_internal = False; choice_made_internal = None\n",
    "                    can_app_int = best_append_internal and best_append_internal[2] < CONNECTION_THRESHOLD\n",
    "                    can_pre_int = best_prepend_internal and best_prepend_internal[2] < CONNECTION_THRESHOLD\n",
    "\n",
    "                    if can_app_int and can_pre_int: choice_made_internal = \"append\" if best_append_internal[2] <= best_prepend_internal[2] else \"prepend\"\n",
    "                    elif can_app_int: choice_made_internal = \"append\"\n",
    "                    elif can_pre_int: choice_made_internal = \"prepend\"\n",
    "\n",
    "                    if choice_made_internal == \"append\":\n",
    "                        idx_rem_int, seg_to_add_int, _ = best_append_internal\n",
    "                        current_merged_internal.append(seg_to_add_int)\n",
    "                        chain_c_end_atom_internal = seg_to_add_int.c_atom\n",
    "                        remaining_internal.pop(idx_rem_int); added_in_iter_internal = True\n",
    "                    elif choice_made_internal == \"prepend\":\n",
    "                        idx_rem_int, seg_to_add_int, _ = best_prepend_internal\n",
    "                        current_merged_internal.insert(0, seg_to_add_int)\n",
    "                        chain_n_end_atom_internal = seg_to_add_int.n_atom\n",
    "                        remaining_internal.pop(idx_rem_int); added_in_iter_internal = True\n",
    "                    if not added_in_iter_internal: break\n",
    "                \n",
    "                if len(current_merged_internal) > best_internal_connection_run[\"num_original_segments\"]:\n",
    "                    best_internal_connection_run[\"connected_segments_ordered\"] = list(current_merged_internal)\n",
    "                    best_internal_connection_run[\"num_original_segments\"] = len(current_merged_internal)\n",
    "\n",
    "            if best_internal_connection_run[\"connected_segments_ordered\"]:\n",
    "                print(f\"  Connecting {best_internal_connection_run['num_original_segments']} unused segments from original chain {original_chain_id_of_unused} into a new chain.\")\n",
    "                secondary_chain_residues = []\n",
    "                segments_for_secondary = best_internal_connection_run[\"connected_segments_ordered\"]\n",
    "                \n",
    "                secondary_chain_residues.extend(segments_for_secondary[0].residues)\n",
    "                current_c_atom_obj_secondary = get_terminal_atom(secondary_chain_residues[-1], 'C')\n",
    "                if not current_c_atom_obj_secondary:\n",
    "                    raise ValueError(f\"Segment {segments_for_secondary[0].id} has no C-terminal C atom for secondary chain.\")\n",
    "\n",
    "                processed_segments_in_this_group_run = set(segments_for_secondary)\n",
    "\n",
    "                for i_sec in range(1, len(segments_for_secondary)):\n",
    "                    prev_seg_sec = segments_for_secondary[i_sec-1]\n",
    "                    curr_seg_sec = segments_for_secondary[i_sec]\n",
    "                    prev_c_sec = current_c_atom_obj_secondary.get_coord()\n",
    "                    next_n_sec = curr_seg_sec.n_atom.get_coord()\n",
    "                    dist_c_n_sec = np.linalg.norm(prev_c_sec - next_n_sec)\n",
    "                    added_glycines_sec = []\n",
    "                    if dist_c_n_sec > PEPTIDE_BOND_THRESHOLD:\n",
    "                        p0_sec, p3_sec = prev_c_sec, next_n_sec\n",
    "                        ca_prev_res_sec, ca_next_res_sec = secondary_chain_residues[-1], curr_seg_sec.residues[0]\n",
    "                        if 'CA' in ca_prev_res_sec and 'CA' in ca_next_res_sec:\n",
    "                            ca_prev_sec, ca_next_sec = ca_prev_res_sec['CA'].get_coord(), ca_next_res_sec['CA'].get_coord()\n",
    "                            v0_sec,v3_sec = p0_sec - ca_prev_sec, p3_sec - ca_next_sec\n",
    "                            p1_sec,p2_sec = p0_sec + v0_sec*0.5, p3_sec + v3_sec*0.5\n",
    "                        else: \n",
    "                            mid_point_sec = (p0_sec+p3_sec)/2.0\n",
    "                            p1_sec,p2_sec = p0_sec+(mid_point_sec-p0_sec)*0.5, p3_sec+(mid_point_sec-p3_sec)*0.5\n",
    "                        ctrl_pts_sec = [p0_sec,p1_sec,p2_sec,p3_sec]\n",
    "                        curve_len_approx_sec = np.linalg.norm(p3_sec-p0_sec)\n",
    "                        num_gly_sec = max(0,int(round(curve_len_approx_sec/CA_CA_DISTANCE))-1)\n",
    "                        if num_gly_sec > 0:\n",
    "                            print(f\"    Secondary chain: adding {num_gly_sec} glycines between ...{prev_seg_sec.id} and {curr_seg_sec.id} (C-N dist: {dist_c_n_sec:.2f} A)\")\n",
    "                            ca_p0_sec = ca_prev_res_sec['CA'].get_coord() if 'CA' in ca_prev_res_sec else p0_sec\n",
    "                            ca_p3_sec = ca_next_res_sec['CA'].get_coord() if 'CA' in ca_next_res_sec else p3_sec\n",
    "                            ca_v0_sec,ca_v3_sec = ca_p0_sec-p0_sec, ca_p3_sec-p3_sec\n",
    "                            ca_ctrl_pts_sec = [ca_p0_sec,ca_p0_sec+ca_v0_sec*0.5,ca_p3_sec+ca_v3_sec*0.5,ca_p3_sec]\n",
    "                            gly_ca_pos_sec_list = [(ca_p0_sec+ca_p3_sec)/2.0] if num_gly_sec==1 and np.linalg.norm(ca_p0_sec-ca_p3_sec)<CA_CA_DISTANCE*1.5 else bezier_curve(ca_ctrl_pts_sec,num_points=num_gly_sec+2)[1:-1]\n",
    "                            curr_conn_c_coord_sec = prev_c_sec\n",
    "                            for k_gly_sec, gly_ca_pos_val_sec in enumerate(gly_ca_pos_sec_list):\n",
    "                                temp_glycine_res_num_counter+=1\n",
    "                                prev_c_this_gly_sec,next_n_this_gly_sec = curr_conn_c_coord_sec, next_n_sec if k_gly_sec==num_gly_sec-1 else None\n",
    "                                gly_res_sec = create_glycine_residue((' ',temp_glycine_res_num_counter,' '),gly_ca_pos_val_sec,prev_c_pos=prev_c_this_gly_sec,next_n_pos=next_n_this_gly_sec)\n",
    "                                added_glycines_sec.append(gly_res_sec)\n",
    "                                curr_conn_c_coord_sec = gly_res_sec['C'].get_coord()\n",
    "                    secondary_chain_residues.extend(added_glycines_sec)\n",
    "                    secondary_chain_residues.extend(curr_seg_sec.residues)\n",
    "                    current_c_atom_obj_secondary = get_terminal_atom(secondary_chain_residues[-1], 'C')\n",
    "                    if not current_c_atom_obj_secondary:\n",
    "                        raise ValueError(f\"Segment {curr_seg_sec.id} resulted in no C-terminal C atom for secondary chain.\")\n",
    "                final_chains_residues.append(secondary_chain_residues)\n",
    "                processed_unused_segments.update(processed_segments_in_this_group_run)\n",
    "            elif segments_to_process_in_group : # No internal connections, but current segment exists\n",
    "                seg_single = segments_to_process_in_group[0] # Process the first one as a single chain\n",
    "                final_chains_residues.append(list(seg_single.residues))\n",
    "                processed_unused_segments.add(seg_single)\n",
    "                print(f\"  Unused segment {seg_single.id} from original chain {original_chain_id_of_unused} forms a separate chain (no internal connection found for this pass).\")\n",
    "            \n",
    "            # Update segments_to_process_in_group for the next iteration of the while loop\n",
    "            segments_to_process_in_group = [s for s in segments_from_one_orig_chain_initial if s not in processed_unused_segments]\n",
    "\n",
    "\n",
    "    # --- 6. Create new PDB structure with all chains ---\n",
    "    new_structure = Structure.Structure('connected_protein_multi')\n",
    "    new_model = Model.Model(0)\n",
    "    \n",
    "    chain_letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "    if len(final_chains_residues) > len(chain_letters):\n",
    "        print(f\"Warning: More than {len(chain_letters)} chains generated ({len(final_chains_residues)}). Some will be skipped in output.\")\n",
    "        final_chains_residues = final_chains_residues[:len(chain_letters)]\n",
    "\n",
    "    for chain_idx, residue_list_for_chain in enumerate(final_chains_residues):\n",
    "        if not residue_list_for_chain: continue\n",
    "\n",
    "        new_chain_id = chain_letters[chain_idx % len(chain_letters)]\n",
    "        new_chain = Chain.Chain(new_chain_id)\n",
    "        \n",
    "        current_residue_seq_num = 1\n",
    "        for original_res in residue_list_for_chain:\n",
    "            new_res = Residue.Residue(original_res.id, original_res.resname, original_res.segid)\n",
    "            for atom in original_res.get_atoms():\n",
    "                new_atom = Atom.Atom(atom.name, atom.coord, atom.bfactor, atom.occupancy,\n",
    "                                     atom.altloc, atom.fullname, 0, \n",
    "                                     element=atom.element, pqr_charge=atom.pqr_charge, radius=atom.radius)\n",
    "                new_res.add(new_atom)\n",
    "            hetfield = original_res.id[0]\n",
    "            new_id = (hetfield, current_residue_seq_num, ' ')\n",
    "            new_res.id = new_id\n",
    "            new_chain.add(new_res)\n",
    "            current_residue_seq_num += 1\n",
    "        \n",
    "        new_model.add(new_chain)\n",
    "        print(f\"Outputting Chain {new_chain_id} with {len(new_chain)} residues.\")\n",
    "\n",
    "    new_structure.add(new_model)\n",
    "    io = PDBIO()\n",
    "    io.set_structure(new_structure)\n",
    "    io.save(output_pdb_path)\n",
    "    print(f\"Successfully processed segments. Output saved to {output_pdb_path}\")\n",
    "\n",
    "\n",
    "\n",
    "connect_broken_chains(r\"C:\\Users\\bashc\\Desktop\\working\\ssBinding\\working8.pdb\",r\"C:\\Users\\bashc\\Desktop\\working\\ssBinding\\connected.pdb\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6911c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
